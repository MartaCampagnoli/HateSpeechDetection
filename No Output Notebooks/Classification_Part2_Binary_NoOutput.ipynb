{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MartaCampagnoli/HateSpeechDetection/blob/main/No%20Output%20Notebooks/Classification_Part2_Binary_NoOutput.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nA7eN_FWUrU1"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import string\n",
        "import nltk\n",
        "import gensim\n",
        "import tensorflow as tf\n",
        "import io\n",
        "import gensim.downloader\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from gensim.models import Word2Vec\n",
        "from google.colab import files\n",
        "from tensorflow import keras\n",
        "from keras.layers import *\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras import models, layers, callbacks, regularizers\n",
        "from keras.models import Model, Sequential, load_model\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.optimizers import Adam\n",
        "from keras.losses import binary_crossentropy\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.metrics import accuracy_score, zero_one_loss, confusion_matrix, classification_report, ConfusionMatrixDisplay\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "from tensorflow.python.ops.numpy_ops import np_config\n",
        "np_config.enable_numpy_behavior()\n",
        "\n",
        "!pip install wget"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GOgZbnMwYSOQ"
      },
      "outputs": [],
      "source": [
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "stemmer = nltk.SnowballStemmer(\"english\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9E6hzmPaIUvP"
      },
      "outputs": [],
      "source": [
        "#modify stopwords list and preprocess data\n",
        "stopwords = nltk.corpus.stopwords.words('english')\n",
        "exceptions = [\"no\", \"not\" , \"don't\", \"they\", \"them\"]\n",
        "stop_words = [word for word in stopwords if word not in exceptions]\n",
        "\n",
        "def preprocess(text):\n",
        "    text = ''.join([word for word in text])\n",
        "    tokens = word_tokenize(text)\n",
        "    tokens = [word for word in tokens if word not in stop_words]\n",
        "    tokens = [stemmer.stem(w) for w in tokens]\n",
        "    return ' '.join(tokens)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_df(dataframe): #label encoder\n",
        "    le = LabelEncoder()\n",
        "    for column in dataframe.columns:\n",
        "        dataframe['label'] = le.fit_transform(dataframe['label'])\n",
        "    return dataframe"
      ],
      "metadata": {
        "id": "k-TxRCTz2VZ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NgHSOPLKsdvF"
      },
      "outputs": [],
      "source": [
        "#Training plots\n",
        "legend_size = 14\n",
        "\n",
        "def performance_plot(history):\n",
        "    plt.figure(figsize=(20,8))\n",
        "\n",
        "    #Loss\n",
        "    plt.subplot(1,2,1)\n",
        "    plt.plot(history.history['loss'])\n",
        "    plt.plot(history.history['val_loss'])\n",
        "    plt.ylabel('loss', size = 12)\n",
        "    plt.xlabel('epoch', size = 12)\n",
        "    plt.legend(['train','val'], fontsize = legend_size)\n",
        "    plt.grid()\n",
        "\n",
        "    #Accuracy\n",
        "    plt.subplot(1,2,2)\n",
        "    plt.plot(history.history['binary_accuracy'])\n",
        "    plt.plot(history.history['val_binary_accuracy'])\n",
        "    plt.ylabel('accuracy', size = 12)\n",
        "    plt.xlabel('epoch', size = 12)\n",
        "    plt.legend(['train','val'], fontsize = legend_size)\n",
        "    plt.grid()\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "earlystopping = callbacks.EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=10, restore_best_weights=True)\n",
        "loss = keras.losses.BinaryCrossentropy()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "uploaded = files.upload() #cleandata.csv"
      ],
      "metadata": {
        "id": "W4DeHXepvl5D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(io.BytesIO(uploaded['cleandata.csv']))"
      ],
      "metadata": {
        "id": "hnLjbOB0vrlL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = encode_df(df)"
      ],
      "metadata": {
        "id": "ctyQV8zIy58i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train, test = train_test_split(df ,test_size=0.30, random_state = 42)"
      ],
      "metadata": {
        "id": "Ggjloon9ueIs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VCsr2pIiQDzV"
      },
      "source": [
        "# Defining the network structures"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aSSqTrT0-uSk"
      },
      "outputs": [],
      "source": [
        "def evaluatemodel(model):\n",
        "  model.evaluate(X_test300, y_test)\n",
        "  y_predictions = model.predict(X_test300)\n",
        "  y_predictions_np = tf.round(y_predictions).numpy()\n",
        "  model_loss = zero_one_loss(y_test, y_predictions_np)\n",
        "  return model_loss, y_predictions_np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9PhS55pS3it4"
      },
      "outputs": [],
      "source": [
        "#cnn\n",
        "def deepcnn(vocab_size, embedding_matrix):\n",
        "  model = Sequential()\n",
        "  model.add(Embedding(vocab_size, 300, weights=[embedding_matrix], input_length=max_length, trainable=False))\n",
        "  model.add(Conv1D(64, 3, padding=\"same\", activation='relu'))\n",
        "  model.add(Conv1D(64, 3, padding=\"same\", activation='relu'))\n",
        "  model.add(Conv1D(64, 3, padding=\"same\", activation='relu'))\n",
        "  model.add(MaxPooling1D(3, padding='same'))\n",
        "  model.add(Dropout(0.5))\n",
        "  model.add(Conv1D(128, 3, padding=\"same\", activation='relu'))\n",
        "  model.add(Conv1D(128, 3, padding=\"same\", activation='relu'))\n",
        "  model.add(Conv1D(128, 3, padding=\"same\", activation='relu'))\n",
        "  model.add(MaxPooling1D(3, padding='same'))\n",
        "  model.add(Dropout(0.4))\n",
        "  model.add(Conv1D(64, 3, padding=\"same\", activation='relu'))\n",
        "  model.add(Conv1D(64, 3, padding=\"same\", activation='relu'))\n",
        "  model.add(Conv1D(64, 3, padding=\"same\", activation='relu'))\n",
        "  model.add(MaxPooling1D(3, padding='same'))\n",
        "  model.add(Dropout(0.3))\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(128, activation='relu'))\n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "  model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['binary_accuracy'])\n",
        "  return model\n",
        "\n",
        "#bilstm\n",
        "\n",
        "def bidlstm(vocab_size, embedding_matrix):\n",
        "  model = Sequential()\n",
        "  model.add(Embedding(vocab_size, 300, weights=[embedding_matrix], input_length=max_length, trainable=False))\n",
        "  model.add(Bidirectional(tf.keras.layers.LSTM(64, return_sequences=True)))\n",
        "  model.add(Bidirectional(tf.keras.layers.LSTM(64, return_sequences=True)))\n",
        "  model.add(Bidirectional(tf.keras.layers.LSTM(64, return_sequences=True)))\n",
        "  model.add(Dropout(0.4))\n",
        "  model.add(Bidirectional(tf.keras.layers.LSTM(32, return_sequences=True)))\n",
        "  model.add(Bidirectional(tf.keras.layers.LSTM(32, return_sequences=True)))\n",
        "  model.add(Bidirectional(tf.keras.layers.LSTM(32)))\n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "  model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['binary_accuracy'])\n",
        "  return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HlgmlbO_grgy"
      },
      "source": [
        "# Pretrained embeddings: CNN and Bidirectional"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a4d20774"
      },
      "outputs": [],
      "source": [
        "#setting training and test\n",
        "X_train, X_test, y_train, y_test = train['text'], test['text'], train['label'], test['label']\n",
        "X_train = X_train.apply(preprocess)\n",
        "X_test = X_test.apply(preprocess)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gmcumgv2ZW4e"
      },
      "outputs": [],
      "source": [
        "#tokenization and padding\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "X_train = tokenizer.texts_to_sequences(X_train)\n",
        "X_test = tokenizer.texts_to_sequences(X_test)\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "max_length = 300\n",
        "X_train300 = pad_sequences(X_train, maxlen=max_length, padding='post')\n",
        "X_test300 = pad_sequences(X_test, maxlen=max_length, padding='post')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fOh2kXnD19w1"
      },
      "outputs": [],
      "source": [
        "#function to try for pretrained models\n",
        "def embedpretr(model, token):\n",
        "  embedding_matrix = np.zeros((vocab_size, 300))\n",
        "  for word, i in token.word_index.items():\n",
        "    if word in model:\n",
        "        embedding_matrix[i] = model[word]\n",
        "  return embedding_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d5QhsCOfk4xM"
      },
      "outputs": [],
      "source": [
        "#Available models in gensim-data\n",
        "print(list(gensim.downloader.info()['models'].keys()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "usI3z6m5oSA5"
      },
      "outputs": [],
      "source": [
        "w2vvectors = gensim.downloader.load('word2vec-google-news-300')\n",
        "fast = gensim.downloader.load('fasttext-wiki-news-subwords-300')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1idk0_MMLFuw"
      },
      "outputs": [],
      "source": [
        "embedding_matrix_pre = embedpretr(w2vvectors, tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T_QgrCErRMrT"
      },
      "outputs": [],
      "source": [
        "#cnn with pretrained w2c\n",
        "pretrainedcnnw = deepcnn(vocab_size, embedding_matrix_pre)\n",
        "history = pretrainedcnnw.fit(X_train300, y_train, epochs=50, batch_size=128, verbose = 0, validation_split=0.1, callbacks=[earlystopping])\n",
        "performance_plot(history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7SDNS7MSL2VQ"
      },
      "outputs": [],
      "source": [
        "#evaluating the cnn\n",
        "zeroloss, predictions = evaluatemodel(pretrainedcnnw)\n",
        "print(f\"Zero_one loss:\", zeroloss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KQbqZQ9cL7GS"
      },
      "outputs": [],
      "source": [
        "print(metrics.classification_report(y_test, predictions))\n",
        "ConfusionMatrixDisplay.from_predictions(y_test, predictions, cmap = 'summer')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WESnXPdlj9JK"
      },
      "outputs": [],
      "source": [
        "pretrainedlstmw = bidlstm(vocab_size, embedding_matrix_pre)\n",
        "history = pretrainedlstmw.fit(X_train300, y_train, epochs=50, batch_size=32, verbose = 0, validation_split=0.1, callbacks=[earlystopping])\n",
        "performance_plot(history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1xTvM376QH5M"
      },
      "outputs": [],
      "source": [
        "zeroloss, predictions = evaluatemodel(pretrainedlstmw)\n",
        "print(f\"Zero_one loss:\", zeroloss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MoQ-R6kXQPhW"
      },
      "outputs": [],
      "source": [
        "print(metrics.classification_report(y_test, predictions))\n",
        "ConfusionMatrixDisplay.from_predictions(y_test, predictions, cmap = 'summer')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4izH7VCtFKQO"
      },
      "outputs": [],
      "source": [
        "#fasttext"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s-LvdehaRoLZ"
      },
      "outputs": [],
      "source": [
        "embedding_matrix_pref = embedpretr(fast, tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SRG_ATRDRTe7"
      },
      "outputs": [],
      "source": [
        "pretrainedcnnf = deepcnn(vocab_size, embedding_matrix_pref)\n",
        "history = pretrainedcnnf.fit(X_train300, y_train, epochs=50, batch_size=128, verbose = 0, validation_split=0.1, callbacks=[earlystopping])\n",
        "performance_plot(history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0qyCM79sSNoO"
      },
      "outputs": [],
      "source": [
        "zeroloss, predictions = evaluatemodel(pretrainedcnnf)\n",
        "print(f\"Zero_one loss:\", zeroloss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U-uNSaG3SU9d"
      },
      "outputs": [],
      "source": [
        "print(metrics.classification_report(y_test, predictions))\n",
        "ConfusionMatrixDisplay.from_predictions(y_test, predictions, cmap = 'summer')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MDKrU7DEkBKC"
      },
      "outputs": [],
      "source": [
        "pretrainedlstmf = bidlstm(vocab_size, embedding_matrix_pref)\n",
        "history = pretrainedlstmf.fit(X_train300, y_train, epochs=50, batch_size=32, verbose = 0, validation_split=0.1, callbacks=[earlystopping])\n",
        "performance_plot(history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0zgYUwsHSc2R"
      },
      "outputs": [],
      "source": [
        "zeroloss, predictions = evaluatemodel(pretrainedlstmf)\n",
        "print(f\"Zero_one loss:\", zeroloss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wAh5yGntSh9u"
      },
      "outputs": [],
      "source": [
        "print(metrics.classification_report(y_test, predictions))\n",
        "ConfusionMatrixDisplay.from_predictions(y_test, predictions, cmap = 'summer')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "V100",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}