{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MartaCampagnoli/HateSpeechDetection/blob/main/No%20Output%20Notebooks/Classification_Part1_MultiClass_NoOutput.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3b297a70",
      "metadata": {
        "scrolled": true,
        "id": "3b297a70"
      },
      "outputs": [],
      "source": [
        "#importing libraries\n",
        "from gensim.models import Word2Vec\n",
        "from google.colab import files\n",
        "import io\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
        "from sklearn.model_selection import train_test_split\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "import re\n",
        "import string\n",
        "from string import punctuation\n",
        "import xgboost as xgb\n",
        "import gensim.downloader\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aa950a88",
      "metadata": {
        "id": "aa950a88"
      },
      "outputs": [],
      "source": [
        "#personalized set of stopwords\n",
        "stopwords = nltk.corpus.stopwords.words('english')\n",
        "exceptions = [\"no\", \"not\" , \"don't\", \"they\", \"them\"]\n",
        "stop = [word for word in stopwords if word not in exceptions]\n",
        "#stemmer\n",
        "stemmer = nltk.SnowballStemmer(\"english\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c13cc68",
      "metadata": {
        "id": "3c13cc68"
      },
      "outputs": [],
      "source": [
        "#preprocessing function\n",
        "def preprocess(text):\n",
        "    text = ''.join([word for word in text])\n",
        "    tokens = word_tokenize(text)\n",
        "    tokens = [word for word in tokens if word not in stop]\n",
        "    tokens = [stemmer.stem(w) for w in tokens]\n",
        "    return ' '.join(tokens)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "uploaded = files.upload() #sixcat.csv"
      ],
      "metadata": {
        "id": "HnpK1jXA3o1Q"
      },
      "id": "HnpK1jXA3o1Q",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(io.BytesIO(uploaded['sixcat.csv'])) #sixcat"
      ],
      "metadata": {
        "id": "BZGhjuT134QC"
      },
      "id": "BZGhjuT134QC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train, test = train_test_split(df ,test_size=0.30, random_state = 42)"
      ],
      "metadata": {
        "id": "8nepTFv94Ct_"
      },
      "id": "8nepTFv94Ct_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a4d20774",
      "metadata": {
        "id": "a4d20774"
      },
      "outputs": [],
      "source": [
        "#setting training and test\n",
        "X_train, X_test, y_train, y_test = train['text'], test['text'], train['target'], test['target']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9a7f8896",
      "metadata": {
        "id": "9a7f8896"
      },
      "outputs": [],
      "source": [
        "X_train = X_train.apply(preprocess)\n",
        "X_test = X_test.apply(preprocess)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9f672889",
      "metadata": {
        "id": "9f672889"
      },
      "outputs": [],
      "source": [
        "#tf idf\n",
        "tf_idf = TfidfVectorizer()\n",
        "X_train_tf = tf_idf.fit_transform(X_train)\n",
        "X_test_tf = tf_idf.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d92fadaa",
      "metadata": {
        "id": "d92fadaa"
      },
      "outputs": [],
      "source": [
        "#for word2vec\n",
        "sentences = [sentence.split() for sentence in X_train]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3cbff033",
      "metadata": {
        "id": "3cbff033"
      },
      "source": [
        "## XGBoost TFIDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eb39a125",
      "metadata": {
        "scrolled": true,
        "id": "eb39a125"
      },
      "outputs": [],
      "source": [
        "model = xgb.XGBClassifier()\n",
        "model.fit(X_train_tf, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6cd35806",
      "metadata": {
        "id": "6cd35806"
      },
      "outputs": [],
      "source": [
        "y_pred = model.predict(X_test_tf)\n",
        "print(metrics.classification_report(y_test, y_pred))\n",
        "ConfusionMatrixDisplay.from_predictions(y_test, y_pred, cmap = 'summer')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6f785d8c",
      "metadata": {
        "id": "6f785d8c"
      },
      "source": [
        "## Logistic Regression TFIDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "097068b8",
      "metadata": {
        "id": "097068b8"
      },
      "outputs": [],
      "source": [
        "model = LogisticRegression(solver='sag', verbose = 1)\n",
        "model.fit(X_train_tf, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3532f31f",
      "metadata": {
        "id": "3532f31f"
      },
      "outputs": [],
      "source": [
        "y_pred = model.predict(X_test_tf)\n",
        "print(classification_report(y_test, y_pred))\n",
        "ConfusionMatrixDisplay.from_predictions(y_test, y_pred, cmap = 'summer')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4608c971",
      "metadata": {
        "id": "4608c971"
      },
      "source": [
        "## SGD TFIDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7294a662",
      "metadata": {
        "id": "7294a662"
      },
      "outputs": [],
      "source": [
        "#sgd\n",
        "sgd = SGDClassifier(random_state=5)\n",
        "sgd.fit(X_train_tf, y_train)\n",
        "y_pred = sgd.predict(X_test_tf)\n",
        "\n",
        "print(classification_report(y_test, y_pred))\n",
        "ConfusionMatrixDisplay.from_predictions(y_test, y_pred, cmap = 'summer')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "52762f34",
      "metadata": {
        "id": "52762f34"
      },
      "source": [
        "## Word2vec: training the embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ee78ea80",
      "metadata": {
        "id": "ee78ea80"
      },
      "outputs": [],
      "source": [
        "w2v_model = Word2Vec(sentences, vector_size=300, window=2, min_count=10, workers=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a7e67a15",
      "metadata": {
        "id": "a7e67a15"
      },
      "outputs": [],
      "source": [
        "def vectorize(sentence):\n",
        "    words = sentence.split()\n",
        "    words_vecs = [w2v_model.wv[word] for word in words if word in w2v_model.wv]\n",
        "    if len(words_vecs) == 0:\n",
        "        return np.zeros(300)\n",
        "    words_vecs = np.array(words_vecs)\n",
        "    return words_vecs.mean(axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5fe78c4c",
      "metadata": {
        "id": "5fe78c4c"
      },
      "outputs": [],
      "source": [
        "X_trainw2c = np.array([vectorize(sentence) for sentence in X_train])\n",
        "X_testw2c = np.array([vectorize(sentence) for sentence in X_test])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b2e3c018",
      "metadata": {
        "scrolled": true,
        "id": "b2e3c018"
      },
      "outputs": [],
      "source": [
        "#xgboost\n",
        "model = xgb.XGBClassifier()\n",
        "model.fit(X_trainw2c, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "140f9c9e",
      "metadata": {
        "id": "140f9c9e"
      },
      "outputs": [],
      "source": [
        "y_pred = model.predict(X_testw2c)\n",
        "print(metrics.classification_report(y_test, y_pred))\n",
        "ConfusionMatrixDisplay.from_predictions(y_test, y_pred, cmap = 'summer')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "080a3ef2",
      "metadata": {
        "id": "080a3ef2"
      },
      "outputs": [],
      "source": [
        "#sgd\n",
        "sgd = SGDClassifier(random_state=5)\n",
        "sgd.fit(X_trainw2c, y_train)\n",
        "y_pred = sgd.predict(X_testw2c)\n",
        "\n",
        "print(classification_report(y_test, y_pred))\n",
        "ConfusionMatrixDisplay.from_predictions(y_test, y_pred, cmap = 'summer')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3c78a13b",
      "metadata": {
        "id": "3c78a13b"
      },
      "source": [
        "## Word2Vec: pretrained embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a4d541f3",
      "metadata": {
        "id": "a4d541f3"
      },
      "outputs": [],
      "source": [
        "# Show all available models in gensim-data\n",
        "print(list(gensim.downloader.info()['models'].keys()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5ce1a56b",
      "metadata": {
        "id": "5ce1a56b"
      },
      "outputs": [],
      "source": [
        "w2vvectors =  gensim.downloader.load('word2vec-google-news-300')\n",
        "textfast = gensim.downloader.load('fasttext-wiki-news-subwords-300')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "da5eea03",
      "metadata": {
        "id": "da5eea03"
      },
      "outputs": [],
      "source": [
        "def vectorizew2c(sentence):\n",
        "    words = sentence.split()\n",
        "    words_vecs = [w2vvectors[word] for word in words if word in w2vvectors]\n",
        "    if len(words_vecs) == 0:\n",
        "        return np.zeros(300)\n",
        "    words_vecs = np.array(words_vecs)\n",
        "    return words_vecs.mean(axis=0)\n",
        "\n",
        "def vectorizetextfast(sentence):\n",
        "    words = sentence.split()\n",
        "    words_vecs = [textfast[word] for word in words if word in textfast]\n",
        "    if len(words_vecs) == 0:\n",
        "        return np.zeros(300)\n",
        "    words_vecs = np.array(words_vecs)\n",
        "    return words_vecs.mean(axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6365bc40",
      "metadata": {
        "id": "6365bc40"
      },
      "outputs": [],
      "source": [
        "#word2vec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5745ffcc",
      "metadata": {
        "id": "5745ffcc"
      },
      "outputs": [],
      "source": [
        "X_trainvec = np.array([vectorizew2c(sentence) for sentence in X_train])\n",
        "X_testvec = np.array([vectorizew2c(sentence) for sentence in X_test])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "76366bf0",
      "metadata": {
        "id": "76366bf0"
      },
      "outputs": [],
      "source": [
        "model = xgb.XGBClassifier()\n",
        "model.fit(X_trainvec, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7e2b3e54",
      "metadata": {
        "id": "7e2b3e54"
      },
      "outputs": [],
      "source": [
        "y_pred = model.predict(X_testvec)\n",
        "print(metrics.classification_report(y_test, y_pred))\n",
        "ConfusionMatrixDisplay.from_predictions(y_test, y_pred, cmap = 'summer')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dd8c99c0",
      "metadata": {
        "id": "dd8c99c0"
      },
      "outputs": [],
      "source": [
        "#FastText"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c67ed63",
      "metadata": {
        "id": "3c67ed63"
      },
      "outputs": [],
      "source": [
        "X_traintext = np.array([vectorizetextfast(sentence) for sentence in X_train])\n",
        "X_testtext = np.array([vectorizetextfast(sentence) for sentence in X_test])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6ce2080e",
      "metadata": {
        "id": "6ce2080e"
      },
      "outputs": [],
      "source": [
        "model = xgb.XGBClassifier()\n",
        "model.fit(X_traintext, y_train)\n",
        "y_pred = model.predict(X_testtext)\n",
        "print(metrics.classification_report(y_test, y_pred))\n",
        "ConfusionMatrixDisplay.from_predictions(y_test, y_pred, cmap = 'summer')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}