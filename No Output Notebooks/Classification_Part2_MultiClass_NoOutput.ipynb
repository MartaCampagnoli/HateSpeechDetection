{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MartaCampagnoli/HateSpeechDetection/blob/main/No%20Output%20Notebooks/Classification_Part2_MultiClass_NoOutput.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nA7eN_FWUrU1"
      },
      "outputs": [],
      "source": [
        "import gensim\n",
        "import io\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import string\n",
        "import nltk\n",
        "import gensim.downloader\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from google.colab import files\n",
        "from gensim.models import Word2Vec\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.layers import *\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from sklearn.preprocessing import LabelBinarizer, LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Sequential\n",
        "from keras.preprocessing import text, sequence\n",
        "from keras import utils\n",
        "from keras import models, layers, callbacks, regularizers\n",
        "from keras.models import Model, Sequential, load_model\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.optimizers import Adam\n",
        "from keras.losses import categorical_crossentropy\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import accuracy_score, zero_one_loss, confusion_matrix, classification_report, ConfusionMatrixDisplay\n",
        "from tensorflow.python.ops.numpy_ops import np_config\n",
        "np_config.enable_numpy_behavior()\n",
        "\n",
        "!pip install wget"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GOgZbnMwYSOQ"
      },
      "outputs": [],
      "source": [
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "stemmer = nltk.SnowballStemmer(\"english\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "uploaded = files.upload() #sixcat.csv"
      ],
      "metadata": {
        "id": "XzSQ--mp7WDK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(io.BytesIO(uploaded['sixcat.csv'])) #sixcat"
      ],
      "metadata": {
        "id": "oh7Bk33O42Th"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train, test = train_test_split(df ,test_size=0.30, random_state = 42)"
      ],
      "metadata": {
        "id": "Zc1WW5pB45o5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#modify stopwords list and preprocess data\n",
        "stopwords = nltk.corpus.stopwords.words('english')\n",
        "exceptions = [\"no\", \"not\" , \"don't\", \"they\", \"them\"]\n",
        "stop_words = [word for word in stopwords if word not in exceptions]\n",
        "\n",
        "\n",
        "def preprocess(text):\n",
        "    text = ''.join([word for word in text])\n",
        "    tokens = word_tokenize(text)\n",
        "    tokens = [word for word in tokens if word not in stop_words]\n",
        "    tokens = [stemmer.stem(w) for w in tokens]\n",
        "    return ' '.join(tokens)"
      ],
      "metadata": {
        "id": "bK1QA3JVZj61"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Training plots\n",
        "legend_size = 14\n",
        "\n",
        "def performance_plot(history):\n",
        "    plt.figure(figsize=(20,8))\n",
        "\n",
        "    #Loss\n",
        "    plt.subplot(1,2,1)\n",
        "    plt.plot(history.history['loss'])\n",
        "    plt.plot(history.history['val_loss'])\n",
        "    plt.ylabel('loss', size = 12)\n",
        "    plt.xlabel('epoch', size = 12)\n",
        "    plt.legend(['train','val'], fontsize = legend_size)\n",
        "    plt.grid()\n",
        "\n",
        "    #Accuracy\n",
        "    plt.subplot(1,2,2)\n",
        "    plt.plot(history.history['categorical_accuracy'])\n",
        "    plt.plot(history.history['val_categorical_accuracy'])\n",
        "    plt.ylabel('accuracy', size = 12)\n",
        "    plt.xlabel('epoch', size = 12)\n",
        "    plt.legend(['train','val'], fontsize = legend_size)\n",
        "    plt.grid()\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "earlystopping = callbacks.EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=10, restore_best_weights=True)\n",
        "loss = keras.losses.CategoricalCrossentropy()"
      ],
      "metadata": {
        "id": "NgHSOPLKsdvF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Defining the network structures"
      ],
      "metadata": {
        "id": "VCsr2pIiQDzV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluatemodel(model):\n",
        "  model.evaluate(X_test300, y_test)\n",
        "  y_pred = model.predict(X_test300)\n",
        "  y_pred = np.argmax(y_pred, axis=1)\n",
        "  return  y_pred"
      ],
      "metadata": {
        "id": "aSSqTrT0-uSk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9RqMpsZ5Zf0Z"
      },
      "outputs": [],
      "source": [
        "#cnn\n",
        "def deepcnn(vocab_size, embedding_matrix, num_class):\n",
        "  model = Sequential()\n",
        "  model.add(Embedding(vocab_size, 300, weights=[embedding_matrix], input_length=max_length, trainable=False))\n",
        "  model.add(Conv1D(64, 3, padding=\"same\", activation='relu'))\n",
        "  model.add(Conv1D(64, 3, padding=\"same\", activation='relu'))\n",
        "  model.add(Conv1D(64, 3, padding=\"same\", activation='relu'))\n",
        "  model.add(MaxPooling1D(3, padding='same'))\n",
        "  model.add(Dropout(0.5))\n",
        "  model.add(Conv1D(128, 3, padding=\"same\", activation='relu'))\n",
        "  model.add(Conv1D(128, 3, padding=\"same\", activation='relu'))\n",
        "  model.add(Conv1D(128, 3, padding=\"same\", activation='relu'))\n",
        "  model.add(MaxPooling1D(3, padding='same'))\n",
        "  model.add(Dropout(0.4))\n",
        "  model.add(Conv1D(64, 3, padding=\"same\", activation='relu'))\n",
        "  model.add(Conv1D(64, 3, padding=\"same\", activation='relu'))\n",
        "  model.add(Conv1D(64, 3, padding=\"same\", activation='relu'))\n",
        "  model.add(MaxPooling1D(3, padding='same'))\n",
        "  model.add(Dropout(0.3))\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(128, activation='relu'))\n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(Dense(num_class, activation = 'softmax'))\n",
        "  model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
        "  return model\n",
        "\n",
        "#bilstm\n",
        "\n",
        "def bidlstm(vocab_size, embedding_matrix, num_class):\n",
        "  model = Sequential()\n",
        "  model.add(Embedding(vocab_size, 300, weights=[embedding_matrix], input_length=max_length, trainable=False))\n",
        "  model.add(Bidirectional(tf.keras.layers.LSTM(64, return_sequences=True)))\n",
        "  model.add(Bidirectional(tf.keras.layers.LSTM(64, return_sequences=True)))\n",
        "  model.add(Bidirectional(tf.keras.layers.LSTM(64, return_sequences=True)))\n",
        "  model.add(Dropout(0.4))\n",
        "  model.add(Bidirectional(tf.keras.layers.LSTM(32, return_sequences=True)))\n",
        "  model.add(Bidirectional(tf.keras.layers.LSTM(32, return_sequences=True)))\n",
        "  model.add(Bidirectional(tf.keras.layers.LSTM(32)))\n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(Dense(num_class, activation = 'softmax'))\n",
        "  model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
        "  return model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pretrained embeddings: CNN and Bidirectional\n"
      ],
      "metadata": {
        "id": "B22dQCEXZj69"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a4d20774"
      },
      "outputs": [],
      "source": [
        "#setting training and test\n",
        "X_train, X_test, train_target, test_target = train['text'], test['text'], train['target'], test['target']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9a7f8896"
      },
      "outputs": [],
      "source": [
        "X_train = X_train.apply(preprocess)\n",
        "X_test = X_test.apply(preprocess)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#encoding the labels and saving the number of classes as a variable\n",
        "encoder = LabelEncoder()\n",
        "encoder.fit(train_target)\n",
        "y_train = encoder.transform(train_target)\n",
        "y_test = encoder.transform(test_target)\n",
        "num_classes = np.max(y_train) + 1\n",
        "y_train = utils.to_categorical(y_train, num_classes)\n",
        "y_test = utils.to_categorical(y_test, num_classes)"
      ],
      "metadata": {
        "id": "Xq0nrnaPNdCy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#tokenization and padding\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "X_train = tokenizer.texts_to_sequences(X_train)\n",
        "X_test = tokenizer.texts_to_sequences(X_test)\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "max_length = 300\n",
        "X_train300 = pad_sequences(X_train, maxlen=max_length, padding='post')\n",
        "X_test300 = pad_sequences(X_test, maxlen=max_length, padding='post')"
      ],
      "metadata": {
        "id": "aqEelmhRZj66"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#function to try for pretrained models\n",
        "def embedpretr(model, token):\n",
        "  embedding_matrix = np.zeros((vocab_size, 300))\n",
        "  for word, i in token.word_index.items():\n",
        "    if word in model:\n",
        "        embedding_matrix[i] = model[word]\n",
        "  return embedding_matrix"
      ],
      "metadata": {
        "id": "fOh2kXnD19w1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Available models in gensim-data\n",
        "print(list(gensim.downloader.info()['models'].keys()))"
      ],
      "metadata": {
        "id": "fbWQxEq9Zj6-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w2vvectors = gensim.downloader.load('word2vec-google-news-300')\n",
        "fast = gensim.downloader.load('fasttext-wiki-news-subwords-300')"
      ],
      "metadata": {
        "id": "E1n0WFCkZj6_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_matrix_pre = embedpretr(w2vvectors, tokenizer)"
      ],
      "metadata": {
        "id": "1idk0_MMLFuw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#cnn with pretrained w2c\n",
        "pretrainedcnnw = deepcnn(vocab_size, embedding_matrix_pre, num_classes)\n",
        "history = pretrainedcnnw.fit(X_train300, y_train, epochs=50, batch_size=128, verbose = 0, validation_split=0.1, callbacks=[earlystopping])\n",
        "performance_plot(history)"
      ],
      "metadata": {
        "id": "T_QgrCErRMrT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#evaluating the cnn\n",
        "predictions = evaluatemodel(pretrainedcnnw)"
      ],
      "metadata": {
        "id": "7SDNS7MSL2VQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(metrics.classification_report(test_target, predictions))\n",
        "ConfusionMatrixDisplay.from_predictions(test_target, predictions, cmap = 'summer')"
      ],
      "metadata": {
        "id": "KQbqZQ9cL7GS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pretrainedlstmw = bidlstm(vocab_size, embedding_matrix_pre, num_classes)\n",
        "history = pretrainedlstmw.fit(X_train300, y_train, epochs=50, batch_size=32, verbose = 0, validation_split=0.1, callbacks=[earlystopping])\n",
        "performance_plot(history)"
      ],
      "metadata": {
        "id": "WESnXPdlj9JK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = evaluatemodel(pretrainedlstmw)"
      ],
      "metadata": {
        "id": "1xTvM376QH5M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(metrics.classification_report(test_target, predictions))\n",
        "ConfusionMatrixDisplay.from_predictions(test_target, predictions, cmap = 'summer')"
      ],
      "metadata": {
        "id": "MoQ-R6kXQPhW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#fasttext"
      ],
      "metadata": {
        "id": "4izH7VCtFKQO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_matrix_pref = embedpretr(fast, tokenizer)"
      ],
      "metadata": {
        "id": "s-LvdehaRoLZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pretrainedcnnf = deepcnn(vocab_size, embedding_matrix_pref, num_classes)\n",
        "history = pretrainedcnnf.fit(X_train300, y_train, epochs=50, batch_size=128, verbose = 0, validation_split=0.1, callbacks=[earlystopping])\n",
        "performance_plot(history)"
      ],
      "metadata": {
        "id": "SRG_ATRDRTe7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = evaluatemodel(pretrainedcnnf)"
      ],
      "metadata": {
        "id": "0qyCM79sSNoO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(metrics.classification_report(test_target, predictions))\n",
        "ConfusionMatrixDisplay.from_predictions(test_target, predictions, cmap = 'summer')"
      ],
      "metadata": {
        "id": "U-uNSaG3SU9d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pretrainedlstmf = bidlstm(vocab_size, embedding_matrix_pref, num_classes)\n",
        "history = pretrainedlstmf.fit(X_train300, y_train, epochs=50, batch_size=32, verbose = 0, validation_split=0.1, callbacks=[earlystopping])\n",
        "performance_plot(history)"
      ],
      "metadata": {
        "id": "MDKrU7DEkBKC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = evaluatemodel(pretrainedlstmf)"
      ],
      "metadata": {
        "id": "0zgYUwsHSc2R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(metrics.classification_report(test_target, predictions))\n",
        "ConfusionMatrixDisplay.from_predictions(test_target, predictions, cmap = 'summer')"
      ],
      "metadata": {
        "id": "wAh5yGntSh9u"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "V100",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}